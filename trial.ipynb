{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NH2854\\Downloads\\Text-Summarizer-Streamlit-App-main\\Text-Summarizer-Streamlit-App-main\\textsum\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import base64\n",
    "import os \n",
    "# from PyPDF import PdfFileMerger, PdfFileReader\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "import streamlit as st \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#model and tokenizer loading\n",
    "checkpoint = \"LaMini-Flan-T5-248M\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(checkpoint, device_map='auto', torch_dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 12:16:13.970 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#file loader and preprocessing\n",
    "def file_preprocessing(file):\n",
    "    loader =  PyPDFLoader(file)\n",
    "    pages = loader.load_and_split()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(pages)\n",
    "    final_texts = \"\"\n",
    "    for text in texts:\n",
    "        print(text)\n",
    "        final_texts = final_texts + text.page_content\n",
    "    return final_texts\n",
    "\n",
    "#LLM pipeline\n",
    "def llm_pipeline(filepath):\n",
    "    pipe_sum = pipeline(\n",
    "        'summarization',\n",
    "        model = base_model,\n",
    "        tokenizer = tokenizer,\n",
    "        max_length = 500, \n",
    "        min_length = 50)\n",
    "    input_text = file_preprocessing(filepath)\n",
    "    result = pipe_sum(input_text)\n",
    "    result = result[0]['summary_text']\n",
    "    return result\n",
    "\n",
    "@st.cache_data\n",
    "#function to display the PDF of a given file \n",
    "def displayPDF(file):\n",
    "    # Opening file from file path\n",
    "    with open(file, \"rb\") as f:\n",
    "        base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # Embedding PDF in HTML\n",
    "    pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"100%\" height=\"600\" type=\"application/pdf\"></iframe>'\n",
    "\n",
    "    # Displaying File\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "#streamlit code \n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "def main():\n",
    "    st.title(\"Document Summarization App using Langauge Model\")\n",
    "\n",
    "    uploaded_file = st.file_uploader(\"Upload your PDF file\", type=['pdf'])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        if st.button(\"Summarize\"):\n",
    "            col1, col2 = st.columns(2)\n",
    "            filepath = \"data/\"+uploaded_file.name\n",
    "            with open(filepath, \"wb\") as temp_file:\n",
    "                temp_file.write(uploaded_file.read())\n",
    "            with col1:\n",
    "                st.info(\"Uploaded File\")\n",
    "                pdf_view = displayPDF(filepath)\n",
    "\n",
    "            with col2:\n",
    "                summary = llm_pipeline(filepath)\n",
    "                st.info(\"Summarization Complete\")\n",
    "                st.success(summary)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- loader = PyPDFLoader(\"example_data/layout-parser-paper.pdf\")\n",
    "pages = loader.load_and_split() -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pwd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n",
      "File \u001b[1;32mc:\\Users\\NH2854\\Downloads\\Text-Summarizer-Streamlit-App-main\\Text-Summarizer-Streamlit-App-main\\textsum\\lib\\site-packages\\langchain_community\\document_loaders\\__init__.py:163\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morg_mode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredOrgModeLoader\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    151\u001b[0m     AmazonTextractPDFLoader,\n\u001b[0;32m    152\u001b[0m     MathpixPDFLoader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m     UnstructuredPDFLoader,\n\u001b[0;32m    162\u001b[0m )\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpebblo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PebbloSafeLoader\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolars_dataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolarsDataFrameLoader\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpowerpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredPowerPointLoader\n",
      "File \u001b[1;32mc:\\Users\\NH2854\\Downloads\\Text-Summarizer-Streamlit-App-main\\Text-Summarizer-Streamlit-App-main\\textsum\\lib\\site-packages\\langchain_community\\document_loaders\\pebblo.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpwd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhttp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPStatus\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pwd'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader, PDFMinerLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model and tokenizer loading\n",
    "from encodings import base64_codec\n",
    "\n",
    "\n",
    "checkpoint = \"LaMini-Flan-T5-248M\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(checkpoint, device_map='auto', torch_dtype=torch.float32)\n",
    "\n",
    "#file loader and preprocessing\n",
    "def file_preprocessing(file):\n",
    "    loader =  PyPDFLoader(file)\n",
    "    pages = loader.load_and_split()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(pages)\n",
    "    final_texts = \"\"\n",
    "    for text in texts:\n",
    "        print(text)\n",
    "        final_texts = final_texts + text.page_content\n",
    "    return final_texts\n",
    "\n",
    "#LLM pipeline\n",
    "def llm_pipeline(filepath):\n",
    "    pipe_sum = pipeline(\n",
    "        'summarization',\n",
    "        model = base_model,\n",
    "        tokenizer = tokenizer,\n",
    "        max_length = 500, \n",
    "        min_length = 50)\n",
    "    input_text = file_preprocessing(filepath)\n",
    "    result = pipe_sum(input_text)\n",
    "    result = result[0]['summary_text']\n",
    "    return result\n",
    "\n",
    "@st.cache_data\n",
    "#function to display the PDF of a given file \n",
    "def displayPDF(file):\n",
    "    # Opening file from file path\n",
    "    with open(file, \"rb\") as f:\n",
    "        base64_pdf = base64_codec.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # Embedding PDF in HTML\n",
    "    pdf_display = F'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"100%\" height=\"600\" type=\"application/pdf\"></iframe>'\n",
    "\n",
    "    # Displaying File\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "#streamlit code \n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "def main():\n",
    "    st.title(\"Document Summarization App using Langauge Model\")\n",
    "\n",
    "    uploaded_file = st.file_uploader(\"Upload your PDF file\", type=['pdf'])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        if st.button(\"Summarize\"):\n",
    "            col1, col2 = st.columns(2)\n",
    "            filepath = \"data/\"+uploaded_file.name\n",
    "            with open(filepath, \"wb\") as temp_file:\n",
    "                temp_file.write(uploaded_file.read())\n",
    "            with col1:\n",
    "                st.info(\"Uploaded File\")\n",
    "                pdf_view = displayPDF(filepath)\n",
    "\n",
    "            with col2:\n",
    "                summary = llm_pipeline(filepath)\n",
    "                st.info(\"Summarization Complete\")\n",
    "                st.success(summary)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
